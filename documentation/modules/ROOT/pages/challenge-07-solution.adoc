[#intro-solution]
= ðŸ§žðŸ”¬ Put It Under The Microscope
include::_attributes.adoc[]

Welcome! Don't worry about being hereâ€”it's absolutely okay! This section provides an example solution
to the challenge, offering a step-by-step implementation as a reference to guide you.

Remember, this is just one way to solve the challenge, and your approach might differ depending on
your creativity or specific requirements. Feel free to explore and adapt the solution to make it your own.
The goal is to help you understand the process and give you the confidence to tackle similar challenges
in the future. Let' 's dive in together! ðŸ§žðŸš€

[#tools-solution]
== ðŸ§žðŸ§° Tools

OpenShift provides a robust suite of monitoring tools designed to give you deep insights into the health, performance,
and behavior of your applications and infrastructure. At the core, OpenShift leverages Prometheus for metrics collection,
which provides a powerful and scalable solution for gathering real-time performance data from your clusters and workloads.
Paired with AlertManager, it ensures that critical events are surfaced promptly, helping you take swift action when needed.

For visualization and analysis, OpenShift integrates some dashboards to track metrics and trends effectively.
Additionally, OpenShift provides a logging stack, enabling centralized log management, analysis, and troubleshooting.
Together, these tools empower developers and operators to monitor, debug, and optimize their environments seamlessly.

One of the features includes in the OpenShift Monitoring stack, is a way to have a separate stack to monitor user-defined projects
without impact the monitoring stack for the OpenShift. This capability is called monitoring for user-defined projects and it
was enabled by the cluster-admin as part of the setup of the cluster. For a detailed information of the steps, review
this xref:01-setup.adoc#ocpsetup-monitoring[step] of the setup.

Additionally Red Hat Developer Hub provides and integrates some functionalities to monitor the status of the application.
These capabilities are:

* Metrics for gather insights and monitor performance of the instance. Information link:https://docs.redhat.com/en/documentation/red_hat_developer_hub/1.4/html-single/monitoring_and_logging/index[here]
* Audit logs to register user activities, system events, and data changes. Information link:https://docs.redhat.com/en/documentation/red_hat_developer_hub/1.4/html/audit_log/assembly-audit-log[here].
* Telemetry data for collecting and analyzing to improve the experience. Information link:https://docs.redhat.com/en/documentation/red_hat_developer_hub/1.4/html-single/telemetry_data_collection/index[here].

Additionally, Red Hat Developer Hub can be extended to integrate some plugins of the community to gather more information
and insights. Some of those plugins are:

* link:https://github.com/backstage/community-plugins/blob/main/workspaces/analytics/plugins/analytics-module-matomo/README.md[Analytics Module: Matomo Analytics]
* link:https://backstage.io/docs/plugins/analytics/[Plugin Analytics]

TIP: Those plugins could be installed using the dynamic plugin framework.

[#metrics-solution]
== ðŸ§žðŸ‘¨â€ðŸ”¬ Metrics

Let's enable or integrate some of those tools in our Red Hat Developer Hub and check the metrics and values
we can get.

First we will enable the metrics endpoint and integrate the metrics into the OpenShift Monitoring stack.
The metrics are exposed through an HTTP service endpoint under the `/metrics` canonical name. It is needed
to create a `ServiceMonitor` object to scrape metrics from that service endpoint in a user-defined project.

The ServiceMonitor will depend of the mechanism of operation of Red Hat Developer Hub:

[tabs]
====
By Helm Chart::
+
--
The Helm Chart provides a configuration to create automatically the ServiceMonitor during the Helm release
life cycle. That configuration is similar to:

[.console-input]
[source, yaml, subs="+macros,+attributes"]
----
upstream:
  metrics:
    serviceMonitor:
      enabled: true
      path: /metrics
----

Run this command for your installation integrated with GitHub:

[.console-input]
[source, bash, subs="+macros,+attributes"]
----
helm upgrade --install rhdh \
    openshift-helm-charts/redhat-developer-hub \
    -f ./documentation/modules/ROOT/examples/challenge-07/values-01-github.yaml \
    --set global.clusterRouterBase=$basedomain
----

Or this command for your installation integrated with GitLab:

[.console-input]
[source, bash, subs="+macros,+attributes"]
----
helm upgrade --install rhdh \
    openshift-helm-charts/redhat-developer-hub \
    -f ./documentation/modules/ROOT/examples/challenge-07/values-01-gitlab.yaml \
    --set global.clusterRouterBase=$basedomain
----
--
By Operator::
+
--
Currently, the Red Hat Developer Hub Operator does not support creating a ServiceMonitor by default.
You must complete the following steps to create a ServiceMonitor to scrape metrics from the endpoint.

Here, there is an example of the ServiceMonitor to scrape metrics:

[.console-input]
[source, yaml, subs="+macros,+attributes"]
----
include::example$/challenge-07/service-monitor-operator.yaml[]
----

This command will create it:

[.console-input]
[source, bash, subs="+macros,+attributes"]
----
oc apply -f ./documentation/modules/ROOT/examples/challenge-07/service-monitor-operator.yaml
----
--
====

Once the ServiceMonitor is created, after some minutes to scrape some metrics, the user can visualize
them from the **Developer** perspective in OpenShift in the menu **Observe -> Metrics**.

For example, the following metrics can be reviewed: `catalog_relations_count`, `catalog_entities_count`.

image::challenge-07/rhdh-metrics-dashboard.png[]

Regarding the logs generated (audit-log), those logs are collected by the OpenShift Logging stack of OpenShift.
We can filter audit logs from the OpenShift UI by using the `isAuditLog` field.

This procedure is similar to:

1. From the **Developer** perspective of the OpenShift web console, click the **Topology** tab.
2. From the **Topology** view, click the pod that you want to view audit log data for.
3. From the pod panel, click the **Resources** tab.
4. From the Pods section of the Resources tab, click **View logs**.
5. From the **Logs view**, enter `isAuditLog` into the Search field to filter audit logs from other log types. You can use the arrows to browse the logs containing the `isAuditLog` field.
